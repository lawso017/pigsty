#==============================================================#
# vlagent Configuration - VictoriaLogs Log Collection Agent
# Path: {{ vlagent_config_dir }}/vlagent.yml  
# Generated by Ansible - DO NOT EDIT MANUALLY
#==============================================================#

# Global settings
global:
  scrape_interval: {{ vlagent_scrape_interval }}

# VictoriaLogs remote write endpoint
remoteWrite:
  url: {{ vlagent_remote_write_url }}

# Position tracking
positions:
  filename: {{ vlagent_positions_file }}
  sync_period: 10s
  ignore_invalid_yaml: true

# Log scraping configurations
scrape_configs:

  ################################################################
  #                        Node Logs                            #
  ################################################################
  # Collect system logs on all nodes (equivalent to Promtail nodes job)
  
{% if vlagent_syslog_enabled %}
  # System logs
  - job_name: syslog
    static_configs:
      - targets: ['localhost:0']
        labels:
          job: node
          src: syslog
          instance: "{{ inventory_hostname }}"
          cluster: "{{ node_cluster|default('nodes') }}"
{% if os_package|default('rpm') == 'deb' %}
          __path__: /var/log/syslog
{% else %}
          __path__: /var/log/messages
{% endif %}

  # Kernel messages
  - job_name: dmesg
    static_configs:
      - targets: ['localhost:0']
        labels:
          job: node
          src: dmesg
          instance: "{{ inventory_hostname }}"
          cluster: "{{ node_cluster|default('nodes') }}"
          __path__: /var/log/dmesg

  # Cron logs
  - job_name: cron
    static_configs:
      - targets: ['localhost:0']
        labels:
          job: node
          src: cron
          instance: "{{ inventory_hostname }}"
          cluster: "{{ node_cluster|default('nodes') }}"
          __path__: /var/log/cron
{% endif %}

{% if vlagent_docker_enabled %}
  # Docker container logs (NEW - solves Docker logging issue!)
  - job_name: docker
    docker_sd_configs:
      - host: {{ vlagent_docker_socket }}
        refresh_interval: 5s
        filters:
          - name: "status"
            values: ["running"]
    relabel_configs:
      # Extract container name (remove leading slash)
      - source_labels: [__meta_docker_container_name]
        regex: '/(.*)'
        target_label: container
        replacement: '${1}'
      
      # Extract compose service name
      - source_labels: [__meta_docker_container_label_com_docker_compose_service]
        target_label: service
      
      # Extract compose project name  
      - source_labels: [__meta_docker_container_label_com_docker_compose_project]
        target_label: project
        
      # Extract component label (custom FMP label)
      - source_labels: [__meta_docker_container_label_component]
        target_label: component
        
      # Set common labels
      - target_label: job
        replacement: docker
      - target_label: src
        replacement: docker
      - target_label: instance
        replacement: "{{ inventory_hostname }}"
      - target_label: cluster
        replacement: "{{ node_cluster|default('nodes') }}"
        
      # Set log file path using container ID
      - source_labels: [__meta_docker_container_id]
        target_label: __path__
        replacement: '/var/lib/docker/containers/${1}/${1}-json.log'

    # Pipeline to parse Docker JSON logs
    pipeline_stages:
      - json:
          expressions:
            output: log
            stream: stream
            time: time
      - timestamp:
          source: time  
          format: RFC3339Nano
      - output:
          source: output
{% endif %}

{% if inventory_hostname in groups["infra"]|default([]) %}
  ################################################################
  #                       Infra Logs                            #
  ################################################################
  # Collect nginx logs on infra nodes (equivalent to Promtail infra job)

{% if inventory_hostname in groups['infra']|default([]) and (nginx_enabled is not defined or nginx_enabled|bool) %}
  # Nginx access logs
  - job_name: nginx
    static_configs:
      - targets: ['localhost:0']
        labels:
          job: infra
          src: nginx
          instance: "{{ inventory_hostname }}"
          cluster: "{{ node_cluster|default('nodes') }}"
          __path__: /var/log/nginx/*.log

  # Nginx error logs
  - job_name: nginx-error
    static_configs:
      - targets: ['localhost:0']
        labels:
          job: infra
          src: nginx-error
          instance: "{{ inventory_hostname }}"
          cluster: "{{ node_cluster|default('nodes') }}"
          __path__: /var/log/nginx-error.log
{% endif %}

{% endif %}

{% if pg_cluster is defined and pg_seq is defined %}
  ################################################################
  #                      PostgreSQL Logs                         #
  ################################################################
  # PostgreSQL logs (for database nodes)
  - job_name: postgres
    static_configs:
      - targets: ['localhost:0']
        labels:
          job: pgsql
          src: postgres
          cls: "{{ pg_cluster }}"
          ins: "{{ pg_cluster }}-{{ pg_seq }}"
          instance: "{{ inventory_hostname }}"
          cluster: "{{ node_cluster|default('nodes') }}"
          __path__: {{ pg_log_dir }}/*

{% if patroni_enabled is defined and patroni_enabled|bool %}
  # Patroni logs
  - job_name: patroni
    static_configs:
      - targets: ['localhost:0']
        labels:
          job: pgsql
          src: patroni
          cls: "{{ pg_cluster }}"
          ins: "{{ pg_cluster }}-{{ pg_seq }}"
          instance: "{{ inventory_hostname }}"
          cluster: "{{ node_cluster|default('nodes') }}"
          __path__: {{ patroni_log_dir }}/patroni.log
{% endif %}

{% if pgbackrest_enabled is defined and pgbackrest_enabled|bool %}
  # pgBackRest logs
  - job_name: pgbackrest
    static_configs:
      - targets: ['localhost:0']
        labels:
          job: pgsql
          src: pgbackrest
          cls: "{{ pg_cluster }}"
          ins: "{{ pg_cluster }}-{{ pg_seq }}"
          instance: "{{ inventory_hostname }}"
          cluster: "{{ node_cluster|default('nodes') }}"
          __path__: {{ pgbackrest_log_dir }}/*.log
{% endif %}

{% if pgbouncer_enabled is defined and pgbouncer_enabled|bool %}
  # PgBouncer logs
  - job_name: pgbouncer
    static_configs:
      - targets: ['localhost:0']
        labels:
          job: pgsql
          src: pgbouncer
          cls: "{{ pg_cluster }}"
          ins: "{{ pg_cluster }}-{{ pg_seq }}"
          instance: "{{ inventory_hostname }}"
          cluster: "{{ node_cluster|default('nodes') }}"
          __path__: {{ pgbouncer_log_dir }}/pgbouncer.log
{% endif %}

{% endif %}

{% if redis_cluster is defined and redis_node is defined %}
  ################################################################
  #                         Redis Logs                           #
  ################################################################
  # Collect redis logs (equivalent to Promtail redis job)
  - job_name: redis
    static_configs:
      - targets: ['localhost:0']
        labels:
          job: redis
          src: redis
          cls: "{{ redis_cluster }}"
          ins: "{{ redis_cluster }}-{{ redis_node }}"
          instance: "{{ inventory_hostname }}"
          cluster: "{{ node_cluster|default('nodes') }}"
          __path__: /var/log/redis/*.log
{% endif %}