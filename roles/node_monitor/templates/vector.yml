#==============================================================#
# Vector Configuration - Log Collection Agent  
# Path: {{ vector_config_dir }}/vector.yaml
# Generated by Ansible - DO NOT EDIT MANUALLY
# Aligned with Promtail configuration in node_monitor role
#==============================================================#

# Global settings
data_dir: "{{ vector_data_dir }}"

# API disabled - using only Prometheus metrics exporter
api:
  enabled: false

################################################################
#                        SOURCES                              #
################################################################

sources:
  ################################################################
  #                        Vector Metrics                        #
  ################################################################
  vector_metrics:
    type: internal_metrics

  vector_logs:
    type: internal_logs

  ################################################################
  #                        Node Logs                            #
  ################################################################
  # System logs (equivalent to Promtail nodes job)
  syslog:
    type: file
    include:
{% if os_package|default('rpm') == 'deb' %}
      - "/var/log/syslog"
{% else %}
      - "/var/log/messages"
{% endif %}
    read_from: beginning

  # Kernel messages
  dmesg:
    type: file
    include:
      - "/var/log/dmesg"
    read_from: beginning

  # Cron logs
  cron:
    type: file
    include:
      - "/var/log/cron"
    read_from: beginning

{% if docker_socket_stat.stat.exists %}
  # Docker container logs (only if socket exists)
  docker:
    type: docker_logs
    docker_host: "{{ vector_docker_socket }}"
{% endif %}

{% if inventory_hostname in groups['infra']|default([]) and (nginx_enabled is not defined or nginx_enabled|bool) %}
  ################################################################
  #                       Infra Logs                            #
  ################################################################
  # Nginx access logs
  nginx_access:
    type: file
    include:
      - "/var/log/nginx/*.log"
    read_from: beginning

  # Nginx error logs
  nginx_error:
    type: file
    include:
      - "/var/log/nginx-error.log"
    read_from: beginning
{% endif %}

{% if pg_cluster is defined and pg_seq is defined %}
  ################################################################
  #                      PostgreSQL Logs                        #
  ################################################################
  # PostgreSQL logs
  postgres:
    type: file
    include:
      - "{{ pg_log_dir }}/*"
    read_from: beginning

{% if patroni_enabled is defined and patroni_enabled|bool %}
  # Patroni logs
  patroni:
    type: file
    include:
      - "{{ patroni_log_dir }}/patroni.log"
    read_from: beginning
{% endif %}

{% if pgbackrest_enabled is defined and pgbackrest_enabled|bool %}
  # pgBackRest logs
  pgbackrest:
    type: file
    include:
      - "{{ pgbackrest_log_dir }}/*.log"
    read_from: beginning
    fingerprint:
      strategy: checksum
      lines: 2
{% endif %}

{% if pgbouncer_enabled is defined and pgbouncer_enabled|bool %}
  # PgBouncer logs
  pgbouncer:
    type: file
    include:
      - "{{ pgbouncer_log_dir }}/pgbouncer.log"
    read_from: beginning
{% endif %}
{% endif %}

{% if redis_cluster is defined and redis_node is defined %}
  ################################################################
  #                         Redis Logs                          #
  ################################################################
  # Redis logs
  redis:
    type: file
    include:
      - "/var/log/redis/*.log"
    read_from: beginning
{% endif %}

################################################################
#                      TRANSFORMS                             #
################################################################

transforms:
  ################################################################
  #                     Vector Metrics Enrichment               #
  ################################################################
  # Add missing labels to vector metrics for dashboard compatibility
  vector_metrics_enriched:
    type: remap
    inputs:
      - vector_metrics
    source: |
      .tags.job = "vector"
      .tags.nodename = "{{ nodename }}"
      .tags.instance = "{{ inventory_hostname }}:{{ vector_port }}"

  ################################################################
  #                     Vector Logs Enrichment                  #
  ################################################################
  # Parse and enrich Vector internal logs
  vector_logs_parsed:
    type: remap
    inputs:
      - vector_logs
    source: |
      .cls = "{{ node_cluster|default('nodes') }}"    
      .job = "vector"
      .src = "vector"
      .ins = "{{ nodename }}"      
      .ip = "{{ inventory_hostname }}"

      if !exists(.timestamp) {
        .timestamp = now()
      }
      if !exists(.message) {
        .message = ""
      }

  ################################################################
  #                        Node Transforms                      #
  ################################################################
  # Parse and enrich syslog (equivalent to Promtail nodes job)
  syslog_parsed:
    type: remap
    inputs:
      - syslog
    source: |
      .cls = "{{ node_cluster|default('nodes') }}"    
      .job = "node"
      .src = "syslog"
      .ins = "{{ nodename }}"      
      .ip = "{{ inventory_hostname }}"

      if !exists(.timestamp) {
        .timestamp = now()
      }
      if !exists(.message) {
        .message = ""
      }

  dmesg_parsed:
    type: remap
    inputs:
      - dmesg
    source: |
      .cls = "{{ node_cluster|default('nodes') }}"    
      .job = "node"
      .src = "dmesg"
      .ins = "{{ nodename }}"      
      .ip = "{{ inventory_hostname }}"

      if !exists(.timestamp) {
        .timestamp = now()
      }
      if !exists(.message) {
        .message = ""
      }

  cron_parsed:
    type: remap
    inputs:
      - cron
    source: |
      .cls = "{{ node_cluster|default('nodes') }}"    
      .job = "node"
      .src = "cron"
      .ins = "{{ nodename }}"
      .ip = "{{ inventory_hostname }}"

      if !exists(.timestamp) {
        .timestamp = now()
      }
      if !exists(.message) {
        .message = ""
      }

{% if docker_socket_stat.stat.exists %}
  docker_parsed:
    type: remap
    inputs:
      - docker
    source: |
      .cls = "{{ node_cluster|default('nodes') }}"    
      .job = "docker"
      .src = "docker"
      .ins = "{{ nodename }}"      
      .ip = "{{ inventory_hostname }}"

      .container = .container_name
      .image = .image

      if !exists(.timestamp) {
        .timestamp = .created_at || now()
      }
      if !exists(.message) {
        .message = ""
      }
{% endif %}

{% if inventory_hostname in groups["infra"]|default([]) and (nginx_enabled is not defined or nginx_enabled|bool) %}
  ################################################################
  #                       Infra Transforms                      #
  ################################################################
  # Parse and enrich Nginx access logs
  nginx_access_parsed:
    type: remap
    inputs:
      - nginx_access
    source: |
      .cls = "{{ node_cluster|default('nodes') }}"    
      .job = "infra"
      .src = "nginx"
      .ins = "{{ nodename }}"
      .ip = "{{ inventory_hostname }}"

      if !exists(.timestamp) {
        .timestamp = now()
      }
      if !exists(.message) {
        .message = ""
      }

  # Parse and enrich Nginx error logs
  nginx_error_parsed:
    type: remap
    inputs:
      - nginx_error
    source: |
      .cls = "{{ node_cluster|default('nodes') }}"    
      .job = "infra"
      .src = "nginx-error"
      .ins = "{{ nodename }}"      
      .ip = "{{ inventory_hostname }}"

      if !exists(.timestamp) {
        .timestamp = now()
      }
      if !exists(.message) {
        .message = ""
      }
{% endif %}

{% if pg_cluster is defined and pg_seq is defined %}
  ################################################################
  #                    PostgreSQL Transforms                    #
  ################################################################
  # Parse and enrich PostgreSQL logs
  postgres_parsed:
    type: remap
    inputs:
      - postgres
    source: |
      .cls = "{{ pg_cluster }}" 
      .job = "pgsql"
      .src = "postgres"
      .ins = "{{ pg_cluster }}-{{ pg_seq }}"
      .ip = "{{ inventory_hostname }}"

      # Parse JSON and flatten all fields automatically
      parsed, err = parse_json(.message)
      if err == null {
        . = merge!(., parsed)

        # Override the message field for searchability
        .message = parsed.message || ""

        # Use PostgreSQL's timestamp if available
        if exists(parsed.timestamp) {
          .timestamp = parse_timestamp!(parsed.timestamp, format: "%Y-%m-%d %H:%M:%S%.3f %Z")
        } else {
          .timestamp = now()
        }
      } else {
        # If JSON parsing fails, keep original message
        .message = .message || ""
        .timestamp = now()
      }

{% if patroni_enabled is defined and patroni_enabled|bool %}
  # Parse and enrich Patroni logs
  patroni_parsed:
    type: remap
    inputs:
      - patroni
    source: |
      .cls = "{{ pg_cluster }}"    
      .job = "pgsql"
      .src = "patroni"
      .ins = "{{ pg_cluster }}-{{ pg_seq }}"
      .ip = "{{ inventory_hostname }}"

      if !exists(.timestamp) {
        .timestamp = now()
      }
      if !exists(.message) {
        .message = ""
      }
{% endif %}

{% if pgbackrest_enabled is defined and pgbackrest_enabled|bool %}
  # Parse and enrich pgBackRest logs
  pgbackrest_parsed:
    type: remap
    inputs:
      - pgbackrest
    source: |
      .cls = "{{ pg_cluster }}"    
      .job = "pgsql"
      .src = "pgbackrest"
      .ins = "{{ pg_cluster }}-{{ pg_seq }}"
      .ip = "{{ inventory_hostname }}"

      if !exists(.timestamp) {
        .timestamp = now()
      }
      if !exists(.message) {
        .message = ""
      }
{% endif %}

{% if pgbouncer_enabled is defined and pgbouncer_enabled|bool %}
  # Parse and enrich PgBouncer logs
  pgbouncer_parsed:
    type: remap
    inputs:
      - pgbouncer
    source: |
      .cls = "{{ pg_cluster }}"    
      .job = "pgsql"
      .src = "pgbouncer"
      .ins = "{{ pg_cluster }}-{{ pg_seq }}"
      .ip = "{{ inventory_hostname }}"

      if !exists(.timestamp) {
        .timestamp = now()
      }
      if !exists(.message) {
        .message = ""
      }
{% endif %}
{% endif %}

{% if redis_cluster is defined and redis_node is defined %}
  ################################################################
  #                       Redis Transforms                      #
  ################################################################
  # Parse and enrich Redis logs
  redis_parsed:
    type: remap
    inputs:
      - redis
    source: |
      .cls = "{{ redis_cluster }}"    
      .job = "redis"
      .src = "redis"
      .ins = "{{ redis_cluster }}-{{ redis_node }}"
      .ip = "{{ inventory_hostname }}"

      if !exists(.timestamp) {
        .timestamp = now()
      }
      if !exists(.message) {
        .message = ""
      }
{% endif %}

################################################################
#                         SINKS                               #
################################################################

sinks:
{% for infra_host in groups['infra']|default([]) %}
  # Send directly to VictoriaLogs instance {{ loop.index }}
  victorialogs_{{ loop.index }}:
    type: http
    inputs:
      - syslog_parsed
      - dmesg_parsed
      - cron_parsed
      - vector_logs_parsed
{% if docker_socket_stat.stat.exists %}
      - docker_parsed
{% endif %}
{% if inventory_hostname in groups["infra"]|default([]) and (nginx_enabled is not defined or nginx_enabled|bool) %}
      - nginx_access_parsed
      - nginx_error_parsed
{% endif %}
{% if pg_cluster is defined and pg_seq is defined %}
      - postgres_parsed
{% if patroni_enabled is defined and patroni_enabled|bool %}
      - patroni_parsed
{% endif %}
{% if pgbackrest_enabled is defined and pgbackrest_enabled|bool %}
      - pgbackrest_parsed
{% endif %}
{% if pgbouncer_enabled is defined and pgbouncer_enabled|bool %}
      - pgbouncer_parsed
{% endif %}
{% endif %}
{% if redis_cluster is defined and redis_node is defined %}
      - redis_parsed
{% endif %}

    # VictoriaLogs endpoint
    uri: "http://{{ infra_host }}:{{ victoria_logs_port|default(3100) }}/insert/jsonline"

    # Headers for VictoriaLogs (matching Promtail external_labels)
    request:
      headers:
        VL-Stream-Fields: "{{ vector_stream_fields }}"
        VL-Time-Field: "{{ vector_time_field }}"
        VL-Msg-Field: "{{ vector_msg_field }}"
        AccountID: "0"
        ProjectID: "0"

    # Encoding
    encoding:
      codec: json

    framing:
      method: newline_delimited

    # Performance settings
    compression: "{{ vector_compression }}"
    healthcheck:
      enabled: {{ vector_healthcheck_enabled | lower }}

    buffer:
      type: memory
      max_events: {{ vector_buffer_max_events }}
      when_full: "{{ vector_buffer_when_full }}"

    batch:
      max_events: {{ vector_batch_max_events }}
      timeout_ms: {{ vector_batch_timeout_ms }}

{% endfor %}

  # Expose Vector metrics for Prometheus scraping
  vector_metrics_http:
    type: prometheus_exporter
    inputs:
      - vector_metrics_enriched
    address: "0.0.0.0:{{ vector_port }}"
    default_namespace: vector
