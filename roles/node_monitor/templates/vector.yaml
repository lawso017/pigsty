#==============================================================#
# Vector Configuration - Log Collection Agent  
# Path: {{ vector_config_dir }}/vector.yaml
# Generated by Ansible - DO NOT EDIT MANUALLY
# Aligned with Promtail configuration in node_monitor role
#==============================================================#

# Global settings
data_dir: "{{ vector_data_dir }}"

# API configuration
api:
  enabled: true
  address: "127.0.0.1:{{ vector_port }}"

################################################################
#                        SOURCES                              #
################################################################

sources:
  ################################################################
  #                        Vector Metrics                        #
  ################################################################
  vector_metrics:
    type: internal_metrics

  ################################################################
  #                        Node Logs                            #
  ################################################################
  # System logs (equivalent to Promtail nodes job)
  syslog:
    type: file
    include:
{% if os_package|default('rpm') == 'deb' %}
      - "/var/log/syslog"
{% else %}
      - "/var/log/messages"
{% endif %}
    read_from: beginning

  # Kernel messages
  dmesg:
    type: file
    include:
      - "/var/log/dmesg"
    read_from: beginning

  # Cron logs
  cron:
    type: file
    include:
      - "/var/log/cron"
    read_from: beginning

{% if docker_socket_stat.stat.exists %}
  # Docker container logs (only if socket exists)
  docker:
    type: docker_logs
    docker_host: "{{ vector_docker_socket }}"
{% endif %}

{% if inventory_hostname in groups["infra"]|default([]) %}
  ################################################################
  #                       Infra Logs                            #
  ################################################################
{% if inventory_hostname in groups['infra']|default([]) and (nginx_enabled is not defined or nginx_enabled|bool) %}
  # Nginx access logs
  nginx_access:
    type: file
    include:
      - "/var/log/nginx/*.log"
    read_from: beginning

  # Nginx error logs
  nginx_error:
    type: file
    include:
      - "/var/log/nginx-error.log"
    read_from: beginning
{% endif %}
{% endif %}

{% if pg_cluster is defined and pg_seq is defined %}
  ################################################################
  #                      PostgreSQL Logs                        #
  ################################################################
  # PostgreSQL logs
  postgres:
    type: file
    include:
      - "{{ pg_log_dir }}/*"
    read_from: beginning

{% if patroni_enabled is defined and patroni_enabled|bool %}
  # Patroni logs
  patroni:
    type: file
    include:
      - "{{ patroni_log_dir }}/patroni.log"
    read_from: beginning
{% endif %}

{% if pgbackrest_enabled is defined and pgbackrest_enabled|bool %}
  # pgBackRest logs
  pgbackrest:
    type: file
    include:
      - "{{ pgbackrest_log_dir }}/*.log"
    read_from: beginning
{% endif %}

{% if pgbouncer_enabled is defined and pgbouncer_enabled|bool %}
  # PgBouncer logs
  pgbouncer:
    type: file
    include:
      - "{{ pgbouncer_log_dir }}/pgbouncer.log"
    read_from: beginning
{% endif %}
{% endif %}

{% if redis_cluster is defined and redis_node is defined %}
  ################################################################
  #                         Redis Logs                          #
  ################################################################
  # Redis logs
  redis:
    type: file
    include:
      - "/var/log/redis/*.log"
    read_from: beginning
{% endif %}

################################################################
#                      TRANSFORMS                             #
################################################################

transforms:
  ################################################################
  #                        Node Transforms                      #
  ################################################################
  # Parse and enrich syslog (equivalent to Promtail nodes job)
  syslog_parsed:
    type: remap
    inputs:
      - syslog
    source: |
      .job = "node"
      .src = "syslog"
      .ip = "{{ inventory_hostname }}"
      .cls = "{{ node_cluster|default('nodes') }}"
      .ins = "{{ nodename }}"

      if !exists(.timestamp) {
        .timestamp = now()
      }
      if !exists(.message) {
        .message = ""
      }

  # Parse and enrich dmesg
  dmesg_parsed:
    type: remap
    inputs:
      - dmesg
    source: |
      .job = "node"
      .src = "dmesg"
      .ip = "{{ inventory_hostname }}"
      .cls = "{{ node_cluster|default('nodes') }}"
      .ins = "{{ nodename }}"

      if !exists(.timestamp) {
        .timestamp = now()
      }
      if !exists(.message) {
        .message = ""
      }

  # Parse and enrich cron logs
  cron_parsed:
    type: remap
    inputs:
      - cron
    source: |
      .job = "node"
      .src = "cron"
      .ip = "{{ inventory_hostname }}"
      .cls = "{{ node_cluster|default('nodes') }}"
      .ins = "{{ nodename }}"

      if !exists(.timestamp) {
        .timestamp = now()
      }
      if !exists(.message) {
        .message = ""
      }

{% if docker_socket_stat.stat.exists %}
  # Parse and enrich Docker logs
  docker_parsed:
    type: remap
    inputs:
      - docker
    source: |
      .job = "docker"
      .src = "docker"
      .ip = "{{ inventory_hostname }}"
      .cls = "{{ node_cluster|default('nodes') }}"
      .ins = "{{ nodename }}"

      .container = .container_name
      .image = .image

      if !exists(.timestamp) {
        .timestamp = .created_at || now()
      }
      if !exists(.message) {
        .message = ""
      }
{% endif %}

{% if inventory_hostname in groups["infra"]|default([]) and (nginx_enabled is not defined or nginx_enabled|bool) %}
  ################################################################
  #                       Infra Transforms                      #
  ################################################################
  # Parse and enrich Nginx access logs
  nginx_access_parsed:
    type: remap
    inputs:
      - nginx_access
    source: |
      .job = "infra"
      .src = "nginx"
      .ip = "{{ inventory_hostname }}"
      .cls = "{{ node_cluster|default('nodes') }}"
      .ins = "{{ nodename }}"

      if !exists(.timestamp) {
        .timestamp = now()
      }
      if !exists(.message) {
        .message = ""
      }

  # Parse and enrich Nginx error logs
  nginx_error_parsed:
    type: remap
    inputs:
      - nginx_error
    source: |
      .job = "infra"
      .src = "nginx-error"
      .ip = "{{ inventory_hostname }}"
      .cls = "{{ node_cluster|default('nodes') }}"
      .ins = "{{ nodename }}"

      if !exists(.timestamp) {
        .timestamp = now()
      }
      if !exists(.message) {
        .message = ""
      }
{% endif %}

{% if pg_cluster is defined and pg_seq is defined %}
  ################################################################
  #                    PostgreSQL Transforms                    #
  ################################################################
  # Parse and enrich PostgreSQL logs
  postgres_parsed:
    type: remap
    inputs:
      - postgres
    source: |
      .job = "pgsql"
      .src = "postgres"
      .cls = "{{ pg_cluster }}"
      .ins = "{{ pg_cluster }}-{{ pg_seq }}"
      .ip = "{{ inventory_hostname }}"

      if !exists(.timestamp) {
        .timestamp = .timestamp || now()
      }
      if !exists(.message) {
        .message = .log || ""
      }

{% if patroni_enabled is defined and patroni_enabled|bool %}
  # Parse and enrich Patroni logs
  patroni_parsed:
    type: remap
    inputs:
      - patroni
    source: |
      .job = "pgsql"
      .src = "patroni"
      .cls = "{{ pg_cluster }}"
      .ins = "{{ pg_cluster }}-{{ pg_seq }}"
      .ip = "{{ inventory_hostname }}"

      if !exists(.timestamp) {
        .timestamp = now()
      }
      if !exists(.message) {
        .message = ""
      }
{% endif %}

{% if pgbackrest_enabled is defined and pgbackrest_enabled|bool %}
  # Parse and enrich pgBackRest logs
  pgbackrest_parsed:
    type: remap
    inputs:
      - pgbackrest
    source: |
      .job = "pgsql"
      .src = "pgbackrest"
      .cls = "{{ pg_cluster }}"
      .ins = "{{ pg_cluster }}-{{ pg_seq }}"
      .ip = "{{ inventory_hostname }}"

      if !exists(.timestamp) {
        .timestamp = now()
      }
      if !exists(.message) {
        .message = ""
      }
{% endif %}

{% if pgbouncer_enabled is defined and pgbouncer_enabled|bool %}
  # Parse and enrich PgBouncer logs
  pgbouncer_parsed:
    type: remap
    inputs:
      - pgbouncer
    source: |
      .job = "pgsql"
      .src = "pgbouncer"
      .cls = "{{ pg_cluster }}"
      .ins = "{{ pg_cluster }}-{{ pg_seq }}"
      .ip = "{{ inventory_hostname }}"

      if !exists(.timestamp) {
        .timestamp = now()
      }
      if !exists(.message) {
        .message = ""
      }
{% endif %}
{% endif %}

{% if redis_cluster is defined and redis_node is defined %}
  ################################################################
  #                       Redis Transforms                      #
  ################################################################
  # Parse and enrich Redis logs
  redis_parsed:
    type: remap
    inputs:
      - redis
    source: |
      .job = "redis"
      .src = "redis"
      .cls = "{{ redis_cluster }}"
      .ins = "{{ redis_cluster }}-{{ redis_node }}"
      .ip = "{{ inventory_hostname }}"

      if !exists(.timestamp) {
        .timestamp = now()
      }
      if !exists(.message) {
        .message = ""
      }
{% endif %}

################################################################
#                         SINKS                               #
################################################################

sinks:
{% for infra_host in groups['infra']|default([]) %}
  # Send directly to VictoriaLogs instance {{ loop.index }}
  victorialogs_{{ loop.index }}:
    type: http
    inputs:
      # Node logs (always included)
      - syslog_parsed
      - dmesg_parsed
      - cron_parsed
{% if docker_socket_stat.stat.exists %}
      # Docker logs (if Docker available)
      - docker_parsed
{% endif %}
{% if inventory_hostname in groups["infra"]|default([]) and (nginx_enabled is not defined or nginx_enabled|bool) %}
      # Infra logs (if on infra node and nginx enabled)
      - nginx_access_parsed
      - nginx_error_parsed
{% endif %}
{% if pg_cluster is defined and pg_seq is defined %}
      # PostgreSQL logs (if on database node)
      - postgres_parsed
{% if patroni_enabled is defined and patroni_enabled|bool %}
      - patroni_parsed
{% endif %}
{% if pgbackrest_enabled is defined and pgbackrest_enabled|bool %}
      - pgbackrest_parsed
{% endif %}
{% if pgbouncer_enabled is defined and pgbouncer_enabled|bool %}
      - pgbouncer_parsed
{% endif %}
{% endif %}
{% if redis_cluster is defined and redis_node is defined %}
      # Redis logs (if on redis node)
      - redis_parsed
{% endif %}

    # VictoriaLogs endpoint
    uri: "http://{{ infra_host }}:{{ victoria_logs_port|default(3100) }}/insert/jsonline"

    # Headers for VictoriaLogs (matching Promtail external_labels)
    request:
      headers:
        VL-Stream-Fields: "{{ vector_stream_fields }}"
        VL-Time-Field: "{{ vector_time_field }}"
        VL-Msg-Field: "{{ vector_msg_field }}"
        AccountID: "0"
        ProjectID: "0"

    # Encoding
    encoding:
      codec: json

    framing:
      method: newline_delimited

    # Performance settings
    compression: "{{ vector_compression }}"
    healthcheck:
      enabled: {{ vector_healthcheck_enabled | lower }}

    buffer:
      type: memory
      max_events: {{ vector_buffer_max_events }}
      when_full: "{{ vector_buffer_when_full }}"

    batch:
      max_events: {{ vector_batch_max_events }}
      timeout_ms: {{ vector_batch_timeout_ms }}

{% endfor %}

  # Expose Vector metrics for Prometheus scraping
  vector_metrics_http:
    type: prometheus_exporter
    inputs:
      - vector_metrics
    address: "0.0.0.0:{{ vector_port }}"
    default_namespace: vector
